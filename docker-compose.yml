services:
  common-validator: &common-validator
    image: ghcr.io/synapsec-ai/llm-defender-validator:v0.9.3
    restart: unless-stopped
    pull_policy: always
    user: llm-defender-user
    ports:
      - "6000:6000"
    volumes:
      - llm-defender-subnet:/home/llm-defender-user/.llm-defender-subnet
      - ${HOME}/.bittensor:/home/llm-defender-user/.bittensor
  llm-defender-api: &llm-defender-api
    restart: unless-stopped
    pull_policy: always
    image: ghcr.io/synapsec-ai/llm-defender-api:v0.9.3
    command: /bin/bash -c "source /llm-defender-subnet/.venv/bin/activate && python3 /llm-defender-subnet/llm_defender/subnet_api/main.py"
    ports:
      - "8080:8080"
    volumes:
      - ${HOME}/.bittensor:/home/llm-defender-user/.bittensor
    environment:
      - NETUID=${NETUID}
      - SUBTENSOR_CHAIN_ENDPOINT=${SUBTENSOR_CHAIN_ENDPOINT}
      - WALLET_NAME=${VALIDATOR_WALLET}
      - WALLET_HOTKEY=${VALIDATOR_HOTKEY}
      - API_LOG_LEVEL=${LOG_LEVEL}
      - TOP_AXONS_ONLY=${TOP_AXONS_ONLY}
      - AXONS_TO_QUERY=${AXONS_TO_QUERY}

  llm-defender-validator-debug-mode:
    <<: *common-validator
    command: /bin/bash -c "source /llm-defender-subnet/.venv/bin/activate && python3 /llm-defender-subnet/llm_defender/neurons/validator.py --netuid ${NETUID} --subtensor.chain_endpoint ${SUBTENSOR_CHAIN_ENDPOINT} --wallet.name ${VALIDATOR_WALLET} --wallet.hotkey ${VALIDATOR_HOTKEY} --log_level ${LOG_LEVEL} --debug_mode"
  
  llm-defender-validator-remote-vllm:
    <<: *common-validator
    command: /bin/bash -c "source /llm-defender-subnet/.venv/bin/activate && python3 /llm-defender-subnet/llm_defender/neurons/validator.py --netuid ${NETUID} --subtensor.chain_endpoint ${SUBTENSOR_CHAIN_ENDPOINT} --wallet.name ${VALIDATOR_WALLET} --wallet.hotkey ${VALIDATOR_HOTKEY} --log_level ${LOG_LEVEL} --vllm_base_url ${VLLM_BASE_URL} --vllm_api_key ${VLLM_API_KEY}"

  llm-defender-validator:
    <<: *common-validator
    depends_on: 
      - prompt-generation-api
    command: /bin/bash -c "source /llm-defender-subnet/.venv/bin/activate && python3 /llm-defender-subnet/llm_defender/neurons/validator.py --netuid ${NETUID} --subtensor.chain_endpoint ${SUBTENSOR_CHAIN_ENDPOINT} --wallet.name ${VALIDATOR_WALLET} --wallet.hotkey ${VALIDATOR_HOTKEY} --log_level ${LOG_LEVEL}"
  
  llm-defender-validator-debug-mode-dev:
    <<: *common-validator
    build:
      context: .
      dockerfile: validator.Dockerfile
    command: /bin/bash -c "source /llm-defender-subnet/.venv/bin/activate && python3 /llm-defender-subnet/llm_defender/neurons/validator.py --netuid ${NETUID} --subtensor.chain_endpoint ${SUBTENSOR_CHAIN_ENDPOINT} --wallet.name ${VALIDATOR_WALLET} --wallet.hotkey ${VALIDATOR_HOTKEY} --log_level ${LOG_LEVEL} --debug_mode"
  
  llm-defender-validator-remote-vllm-dev:
    <<: *common-validator
    build:
      context: .
      dockerfile: validator.Dockerfile
    command: /bin/bash -c "source /llm-defender-subnet/.venv/bin/activate && python3 /llm-defender-subnet/llm_defender/neurons/validator.py --netuid ${NETUID} --subtensor.chain_endpoint ${SUBTENSOR_CHAIN_ENDPOINT} --wallet.name ${VALIDATOR_WALLET} --wallet.hotkey ${VALIDATOR_HOTKEY} --log_level ${LOG_LEVEL} --vllm_base_url ${VLLM_BASE_URL} --vllm_api_key ${VLLM_API_KEY} --vllm_model_name ${VLLM_MODEL_NAME}"

  llm-defender-validator-dev:
    <<: *common-validator
    build:
      context: .
      dockerfile: validator.Dockerfile
    depends_on: 
      - prompt-generation-api
    command: /bin/bash -c "source /llm-defender-subnet/.venv/bin/activate && python3 /llm-defender-subnet/llm_defender/neurons/validator.py --netuid ${NETUID} --subtensor.chain_endpoint ${SUBTENSOR_CHAIN_ENDPOINT} --wallet.name ${VALIDATOR_WALLET} --wallet.hotkey ${VALIDATOR_HOTKEY} --log_level ${LOG_LEVEL}"
  
  prompt-generation-api:
    restart: unless-stopped
    image: vllm/vllm-openai:v0.5.0
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ipc: host
    command: [
      "--model", "${VLLM_MODEL_NAME}",
      "--tensor-parallel-size", "${TENSOR_PARALLEL_SIZE}"
    ]
    volumes:
      - ${HOME}/.cache/huggingface:/root/.cache/huggingface

  llm-defender-api-dev:
    <<: *llm-defender-api
    build:
      context: .
      dockerfile: api.Dockerfile

volumes:
  llm-defender-subnet:
